{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Crear videos pix2pix_nature.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joseortegalabra/Proyect-GANs/blob/master/Crear_videos_pix2pix_nature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoJGLCooDsx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3e1df222-5a93-47f1-8004-0f9112cd059b"
      },
      "source": [
        "#crear frames para videos con red pix2pix\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython import display\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltmDMs0IQRHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset de imagenes de edificios de praga - frontis\n",
        "class mydata():\n",
        "  def __init__(self):\n",
        "    #DATA VIDEO\n",
        "    !unrar x '/content/drive/My Drive/Proyecto GANs MLBI/dog select.mp4.rar'  \n",
        "    self.path = '/content/dog select.mp4/'\n",
        "    path_frame_original = [arch for arch in listdir(self.path) if isfile(join(self.path, arch))] \n",
        "    self.path_img = [str(x) + '.jpg' for x in range(len(path_frame_original))]\n",
        "\n",
        "    #hiperparametros imagenes\n",
        "    self.img_width = 256   \n",
        "    self.img_height = 256  \n",
        "\n",
        "  def load(self, image_file):   \n",
        "    image = tf.io.read_file(image_file)\n",
        "    image = tf.image.decode_jpeg(image)    \n",
        "    w = tf.shape(image)[1]       \n",
        "    w = w // 2     \n",
        "    real_image = image[:, :w, :]      \n",
        "    input_image = image[:, w:, :]      \n",
        "    input_image = tf.cast(input_image, tf.float32)   \n",
        "    real_image = tf.cast(real_image, tf.float32)\n",
        "    return input_image, real_image\n",
        "\n",
        "  def normalize(self, input_image, real_image):   \n",
        "    input_image = (input_image / 127.5) - 1\n",
        "    real_image = (real_image / 127.5) - 1\n",
        "    return input_image, real_image\n",
        "\n",
        "  def load_image_test(self, image_file):   \n",
        "    input_image, real_image = self.load(image_file)  \n",
        "    input_image, real_image = self.normalize(input_image, real_image)  \n",
        "    return input_image, real_image\n",
        "  \n",
        "  def create_data_video(self, i):\n",
        "    inp, tar = self.load_image_test(self.path + self.path_img[i])  #image file i\n",
        "    inp = tf.expand_dims(inp, 0)\n",
        "    tar = tf.expand_dims(tar, 0)\n",
        "    return inp, tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRCNtkhDDyRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class pix2pix():\n",
        "  def __init__(self):\n",
        "    self.loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)    #crear funcion de perdida binaria para evaluar loss GAN\n",
        "    \n",
        "    self.initializer = tf.random_normal_initializer(0., 0.02)     #inicializar los pesos de las capas conv2d, mismo valor que los demas\n",
        "    \n",
        "    self.generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)   #definir optimizadores para el generador y el discriminador\n",
        "    self.discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "    self.epochs = 100    #cantidad de epocas\n",
        "\n",
        "  def downsample(self, filters, size, apply_batchnorm=True):     \n",
        "    '''\n",
        "    crear capa convolusional encoder - reducir dimensionalidad de la imagen.   Crear un modelo secuencial donde solo tiene una capa CONV2D\n",
        "    Cantidad de filtros y tamaño variable. Stride fijo a 2. Padding = 'same'   -> siempre se reduce a la mitad el tamaño de la imagen (ancho y alto)\n",
        "    Reducir dimensionalidad usado en generador y discriminador\n",
        "    (Modelo Secuencial de keras: Sequential groups a linear stack of layers into a tf.keras.Model)\n",
        "    '''\n",
        "\n",
        "    result = tf.keras.Sequential()     #Sequential groups a linear stack of layers into a tf.keras.Model. -> Puedo agrupar varias capas de keras y me devuelve las capas unidas y permitiendo unirlas a otras capas de keras\n",
        "    result.add( tf.keras.layers.Conv2D(filters = filters, kernel_size = size, strides = 2, padding='same', kernel_initializer= self.initializer, use_bias=False))       \n",
        "    \n",
        "    if apply_batchnorm:\n",
        "      result.add(tf.keras.layers.BatchNormalization())   #aplicar batch normalization en el layer de salida\n",
        "\n",
        "    result.add(tf.keras.layers.LeakyReLU())   #aplicar funcion de activacion\n",
        "\n",
        "    return result    #retorna el conjunto de capas CONV2D, batch_normalization y activacion unidas y que se pueden unir a otras capas\n",
        "\n",
        "\n",
        "  def upsample(self, filters, size, apply_dropout=False):\n",
        "    '''\n",
        "    crear capa convolusional decoder - aumentar dimensionalidad de la imagen.   Crear un modelo secuencial donde solo tiene una capa CONV2D TRASPUESTA\n",
        "    Cantidad de filtros y tamaño variable. Stride fijo a 2. Padding = 'same'   -> siempre aumenta al doble el tamaño de la imagen (ancho y alto)\n",
        "    Aumentar la dimensionalidad usado en generador - Crear imagen ficticia a partir del INPUT y de RUIDO GAUSIANO\n",
        "    '''  \n",
        "\n",
        "    result = tf.keras.Sequential()   \n",
        "    result.add(tf.keras.layers.Conv2DTranspose(filters = filters, kernel_size = size, strides = 2, padding='same', kernel_initializer = self.initializer, use_bias=False))\n",
        "    result.add(tf.keras.layers.BatchNormalization())   #siempre se aplica batch normalization\n",
        "\n",
        "    if apply_dropout:\n",
        "        result.add(tf.keras.layers.Dropout(0.5))   #aplicar dropout con probabilidad 0.5  -> RUIDO GAUSIANO\n",
        "\n",
        "    result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    return result    #return es el modelo creado con la capa convolusion traspuesta con ruido gausiano, batch_normalization y relu\n",
        "\n",
        "  \n",
        "  def create_generator(self):  \n",
        "    inputs = tf.keras.layers.Input(shape=[256,256,3])       #crear layer input de tamaño 256x256x3 obtenido del preprocesamiento\n",
        "\n",
        "    #definir lista con la capas convolusionales encoder de la U-NET\n",
        "    down_stack = [\n",
        "      self.downsample(64, 4, apply_batchnorm=False),         #(None, 128, 128, 64)   cada capa me reduce a la mitad la dimensión\n",
        "      self.downsample(128, 4),                               #(None, 64, 64, 128)\n",
        "      self.downsample(256, 4),                               #(None, 32, 32, 256)\n",
        "      self.downsample(512, 4),                               #(None, 16, 16, 512)\n",
        "      self.downsample(512, 4),                               #(None, 8, 8, 512)\n",
        "      self.downsample(512, 4),                               #(None, 4, 4, 512)\n",
        "      self.downsample(512, 4),                               #(None, 2, 2, 512)\n",
        "      self.downsample(512, 4),                               #(None, 1, 1, 512)    #reduzo el espacio latente al ancho y alto más pequeño posible  \n",
        "    ]\n",
        "\n",
        "    #definir lista con las capas de deconvolusión decoder de la U-NET\n",
        "    up_stack = [\n",
        "      self.upsample(512, 4, apply_dropout=True),             # (None, 2, 2, 1024)     #duplico ancho y alto. DUPLICO CANTIDAD DE FILTROS al utilizar los valores del encoder   \n",
        "      self.upsample(512, 4, apply_dropout=True),             # (None, 4, 4, 1024)      \n",
        "      self.upsample(512, 4, apply_dropout=True),             # (None, 8, 8, 1024)\n",
        "      self.upsample(512, 4),                                 # (None, 16, 16, 1024)\n",
        "      self.upsample(256, 4),                                 # (None, 32, 32, 512)\n",
        "      self.upsample(128, 4),                                 # (None, 64, 64, 256)\n",
        "      self.upsample(64, 4),                                  # (None, 128, 128, 128)    #aumento la dimensionalidad hasta el paso anterior a tener la imagen original 256x256\n",
        "    ]\n",
        "\n",
        "    #ultima capa decoder -> (None, 256, 256, 3) y ahora con funcion de activacion tangente hiperbolica\n",
        "    last_decoder = tf.keras.layers.Conv2DTranspose(filters = 3, kernel_size = 4, strides=2, padding='same', kernel_initializer= self.initializer,  activation='tanh') \n",
        "\n",
        "\n",
        "\n",
        "    #---->UNIR CAPAS PARA ARMAR GENERADOR U-NET-----<\n",
        "    x = inputs    #capa de entrada\n",
        "\n",
        "    #ENCODER\n",
        "    results_encoder = []    #voy guardando los resultados de las capas de encoder\n",
        "    for down in down_stack:   #recorro el array con las capas de downsaple\n",
        "      x = down(x)    #obtengo la salida de pasar por la capa encoder\n",
        "      results_encoder.append(x)    #guardo los resultados de pasar por cada una de las capas de downsample\n",
        "    results_encoder = reversed(results_encoder[:-1])    #invierto el orden de los valores y elimino los resultados de la capa (None, 1, 1, 512)    \n",
        "\n",
        "    #DECODER\n",
        "    for up, result_encoder in zip(up_stack, results_encoder):    #hago de upsample considerando el valor obtenido al pasar por cada capa encoder y el paso por cada capa decoder\n",
        "      x = up(x)    #obtengo la salida al pasar por la capa decoder\n",
        "      x = tf.keras.layers.Concatenate()([x, result_encoder])    #apilar los resultados de downsampling con los de upsampling\n",
        "    x = last_decoder(x)    #paso por la ultima capa para obtener la imagen deseada que va al discriminador\n",
        "\n",
        "    self.generator = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "    \n",
        "\n",
        "\n",
        "  def create_discriminator(self):\n",
        "    '''\n",
        "    Discriminador lee la imagen input y la imagen real y devuelve una matriz 30x30 que me permite clasificar si la imagen es real o falsa\n",
        "    '''\n",
        "\n",
        "    input = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')   #input contorno \n",
        "    target = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')  #imagen real\n",
        "\n",
        "    #red discriminador\n",
        "    x = tf.keras.layers.concatenate([input, target])          # (None, 256, 256, channels*2 -> 6)   #unir input y la imagen real\n",
        "    x = self.downsample(64, 4, apply_batchnorm=False)(x)      # (None, 128, 128, 64)  #crear capa downsample y evaluarla inmediatamente en x input\n",
        "    x = self.downsample(128, 4)(x)                            # (None, 64, 64, 128)\n",
        "    x = self.downsample(256, 4)(x)                            # (None, 32, 32, 256) \n",
        "    \n",
        "    #nueva capa zero padding\n",
        "    x = tf.keras.layers.ZeroPadding2D()(x)                # (None, 34, 34, 256)     agregar vector de ceros a todos los lados\n",
        "    \n",
        "    #nueva capa de convlusion downsample con padding valid, batchnormalizacion y activacion leakyrelu      tamaño: [(34 - filtro - 0) / stride]  + 1  \n",
        "    x = tf.keras.layers.Conv2D(filters = 512, kernel_size = 4, strides= 1, kernel_initializer= self.initializer, use_bias=False)(x)# (None, 31, 31, 512)   \n",
        "    x = tf.keras.layers.BatchNormalization()(x)   \n",
        "    x = tf.keras.layers.LeakyReLU()(x)\n",
        "\n",
        "    #nueva capa zero padding\n",
        "    x = tf.keras.layers.ZeroPadding2D()(x)                  # (None , 33, 33, 512)\n",
        "\n",
        "    #nueva capa y ultima convolsion con padding valid, sin batchnormalization y sin activacion ?     tamaño = [(33 - filtro + 0) / stride] + 1\n",
        "    x = tf.keras.layers.Conv2D(filters = 1, kernel_size = 4, strides=1, kernel_initializer=self.initializer)(x) # (None, 30, 30, 1) \n",
        "\n",
        "    #return el model de keras con el input y el output\n",
        "    self.discriminator = tf.keras.Model(inputs=[input, target], outputs=x)\n",
        "\n",
        "\n",
        "\n",
        "  def generator_loss(self, discriminator_generated_output, generated_output, real_image):   \n",
        "    self.LAMBDA = 100    #parametro fijado en el paper - para penalizar norma l1 en la funcion de costos total de la GAN\n",
        "    '''\n",
        "    Loss del Generador. \n",
        "    gan loss = valor 1 contra el valor obtenida en el discriminador de la imagen obtenida en el generador - que tanto engañe al discriminador con la imagen ficticia\n",
        "    l1 loss = Imagen real vs imagen obtenida del generador\n",
        "    Generador busca minimizar su loss, que la imagen ficticia sea clasificada como real.\n",
        "    '''\n",
        "\n",
        "    #comparo valor 1 que el discriminador cree que la imagen es real contra el valor obtenido en el discriminador de la imagen fictia\n",
        "    gan_loss = self.loss_object(tf.ones_like(discriminator_generated_output),   discriminator_generated_output)\n",
        "    \n",
        "    #norma 1 entre la imagen real y la imagen obtenida en el generador\n",
        "    l1_loss = tf.reduce_mean(tf.abs(real_image - generated_output))\n",
        "\n",
        "    #perdida del generador es la suma de la tipica perdida de la gan más la perdida con la norma l1\n",
        "    total_gen_loss = gan_loss + (self.LAMBDA * l1_loss)\n",
        "\n",
        "    return total_gen_loss, gan_loss, l1_loss\n",
        "\n",
        "  def discriminator_loss(self, discrimator_real_output, discriminator_generated_output):\n",
        "    '''\n",
        "    Loss del Discriminador.\n",
        "    real_loss = valor 1 (es una imagen real) contra valor obtenido al pasar la imagen real por el discriminador\n",
        "    generated_loss = valor 0  (es una imagen ficticia) contra valor obtenido al pasar la imagen generada por el discriminador.\n",
        "    Discriminador busca minimizar su loss, que la imagen real sea clasificada como real y que la imagen ficitia sea clasificada como ficticia\n",
        "    '''\n",
        "    real_loss = self.loss_object(tf.ones_like(discrimator_real_output), discrimator_real_output)\n",
        "\n",
        "    generated_loss = self.loss_object(tf.zeros_like(discriminator_generated_output), discriminator_generated_output)\n",
        "\n",
        "    total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "    return total_disc_loss\n",
        "\n",
        "\n",
        "  def generate_images(self, test_input, test_real, save_results = False, index_file = 0): \n",
        "    '''\n",
        "    Funcion creada para mostrar avances de entrenamiento del modelo con una imagen del conjunto de test\n",
        "    Mostrar input, ground truth, generated\n",
        "    '''\n",
        "\n",
        "    #generated_image = self.generator(test_input, training=True)    #especificado por qué le ponen TRUE \n",
        "    generated_image = self.generator(test_input, training=False)\n",
        "\n",
        "    #graficar\n",
        "    fig = plt.figure(figsize=(15,15))\n",
        "\n",
        "    #IMAGEN A MOSTRAR DURANTE EL ENTRENAMIENTO ES LA PRIMERA IMAGEN DEL CONJUNTO DE TEST - PERO ESTA VIENE DEL DATASET Y POR LO TANTO REORDENA LA IMAGEN Y SOLO ME ENTREGA UNA IMAGEN CUALQUIERA\n",
        "    display_list = [test_input[0], test_real[0], generated_image[0]]   #eliminar dimensiones para graficar\n",
        "    \n",
        "    title = ['Input Image', 'Ground Truth', 'Generated Image']\n",
        "\n",
        "    for i in range(3):\n",
        "      plt.subplot(1, 3, i+1)\n",
        "      plt.title(title[i])\n",
        "      # getting the pixel values between [0, 1] to plot it.\n",
        "      plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "      plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "    if(save_results):\n",
        "      fig.savefig(str(index_file), dpi = 150)\n",
        "\n",
        "  def generate_images_2(self, test_input, test_real, save_results = False, index_file = 0): \n",
        "    generated_image = self.generator(test_input, training=False)\n",
        "\n",
        "    #graficar\n",
        "    generated_image_3d = np.squeeze(generated_image)\n",
        "\n",
        " \n",
        "    pil_img = Image.fromarray(((generated_image_3d* 0.5 + 0.5)*255).astype(np.uint8))\n",
        "    \n",
        "    #fig = plt.figure(figsize=(15,15))\n",
        "    #plt.imshow(generated_image_3d * 0.5 + 0.5)\n",
        "    #plt.axis('off')\n",
        "    #plt.show()\n",
        "    \n",
        "    if(save_results):\n",
        "      #fig.savefig(str(index_file), dpi = 150, bbox_inches='tight', pad_inches = 0)  \n",
        "      pil_img.save(str(index_file)+'.png')\n",
        "\n",
        "  def generate_images_discriminator(self, test_input, test_real, save_results = False, index_file = 0):\n",
        "    #generated_image = self.generator(test_input, training=True)    #especificado por que le ponen TRUE \n",
        "    generated_image = self.generator(test_input, training=False)    #especificado por que le ponen TRUE \n",
        "    discriminator_generated_image = self.discriminator([test_input, generated_image], training = False)\n",
        "\n",
        "    discriminator_ground_truth =  self.discriminator([test_input, test_real], training = False)\n",
        "\n",
        "    display_list = [discriminator_generated_image, discriminator_ground_truth]\n",
        "    title = ['Discriminator Generated Image', 'Discriminator Ground Truth']\n",
        "\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    for i in range(2):\n",
        "      plt.subplot(2, 1, i+1)\n",
        "      plt.title(title[i])\n",
        "      #mostrar resultado discriminador de imagen ficticia y real\n",
        "      plt.imshow(display_list[i][0,...,-1], vmin=0, vmax=1, cmap='RdBu_r')\n",
        "      plt.colorbar()\n",
        "      plt.axis('off')\n",
        "    #plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "    if(save_results):\n",
        "      fig.savefig(str(index_file), dpi = 150)\n",
        "\n",
        "  def create_checkpoint(self):\n",
        "    self.checkpoint_dir = './training_checkpoints'\n",
        "    self.checkpoint_prefix = os.path.join(self.checkpoint_dir, \"ckpt\")\n",
        "    self.checkpoint = tf.train.Checkpoint(generator_optimizer=      self.generator_optimizer,\n",
        "                                          discriminator_optimizer=  self.discriminator_optimizer,\n",
        "                                          generator    =            self.generator,\n",
        "                                          discriminator=            self.discriminator)\n",
        "    \n",
        "  @tf.function\n",
        "  def train_step(self, input_image, real_image, num_epoch):\n",
        "    #entrenar con gradient tape\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      \n",
        "      #crear imagen ficticia a partir de una imagen de input\n",
        "      gen_output = self.generator(input_image, training=True)\n",
        "\n",
        "      #discriminador de la imagen input con la imagen real\n",
        "      disc_real_output = self.discriminator([input_image, real_image], training=True)\n",
        "      #discriminador de la imagen input con la imagen generada en el generador\n",
        "      disc_generated_output = self.discriminator([input_image, gen_output], training=True)\n",
        "\n",
        "      #calcular la loss del generador \n",
        "      gen_total_loss, gen_gan_loss, gen_l1_loss = self.generator_loss(disc_generated_output, gen_output, real_image)\n",
        "      # calcular la loss de discriminador\n",
        "      disc_total_loss = self.discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "    \n",
        "    #---->entrenar la red con los gradientes\n",
        "    #calcular gradientes del generador\n",
        "    generator_gradients = gen_tape.gradient(gen_total_loss, self.generator.trainable_variables)\n",
        "    #calcular gradientes del discriminador\n",
        "    discriminator_gradients = disc_tape.gradient(disc_total_loss, self.discriminator.trainable_variables)\n",
        "\n",
        "    #----->aplicar gradiente en el generador\n",
        "    self.generator_optimizer.apply_gradients(zip(generator_gradients, self.generator.trainable_variables))\n",
        "    self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.trainable_variables))\n",
        "\n",
        "\n",
        "    #loss en tensor board\n",
        "    with summary_writer.as_default():\n",
        "      tf.summary.scalar('gen_total_loss', gen_total_loss, step=num_epoch)\n",
        "      tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=num_epoch)\n",
        "      tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=num_epoch)\n",
        "      tf.summary.scalar('disc_loss', disc_total_loss, step=num_epoch)\n",
        "\n",
        "  #funcion para entrenar\n",
        "  def fit(self, train_ds, test_ds):\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      start = time.time()\n",
        "      display.clear_output(wait=True)\n",
        "\n",
        "      #Ejemplo de una imagen del set de TEST por época\n",
        "      for example_input, example_target in test_ds.take(1):    #tomo una sola imagen del dataset de test\n",
        "        self.generate_images(example_input, example_target, save_results = True, index_file = 'Output, epoch: ' +str(epoch))\n",
        "        self.generate_images_discriminator(example_input, example_target, save_results = True, index_file = 'Output Discriminator, epoch: ' +str(epoch))\n",
        "      print(\"Epoch: \", epoch)\n",
        "\n",
        "      # Entrenar el modelo  - TRAIN\n",
        "      for n, (input_image, target) in train_ds.enumerate():\n",
        "        print('.', end='')    #barra progreso\n",
        "        if (n+1) % 100 == 0:\n",
        "          print()\n",
        "        self.train_step(input_image, target, epoch)  #entrenar la red con BATCH TAMAÑO 1\n",
        "      print()\n",
        "\n",
        "      # guardar checkpoint del modelo cada 20 epocas\n",
        "      if (epoch + 1) % 20 == 0:\n",
        "        self.checkpoint.save(file_prefix = self.checkpoint_prefix)\n",
        "\n",
        "      print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time()-start))\n",
        "    self.checkpoint.save(file_prefix = self.checkpoint_prefix)\n",
        "\n",
        "model_gan = pix2pix()     #crear objeto modelo\n",
        "model_gan.create_generator()    #crer modelo generador\n",
        "model_gan.create_discriminator()   #crear modelo discriminador"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBxF6zggzrq4",
        "colab_type": "text"
      },
      "source": [
        "### Load CK\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5EJ4yZ44vFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e09d6561-7468-42db-eb2b-c4a96a333e46"
      },
      "source": [
        "#restoring the latest checkpoint in checkpoint_dir\n",
        "path_ck = '/content/drive/My Drive/CK pix2pix animals (30%)/'   #directorio del ck a cargar\n",
        "model_gan.create_checkpoint()\n",
        "model_gan.checkpoint.restore(tf.train.latest_checkpoint(path_ck))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa455792b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trhbnpeh4wnd",
        "colab_type": "text"
      },
      "source": [
        "### DESCARGAR FRAMES DEL VIDEO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWoHNwGv-spO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3fe5aed-c403-43d2-8bc0-d9a68e3930f7"
      },
      "source": [
        "data_video = mydata()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/My Drive/Proyecto GANs MLBI/dog select.mp4.rar\n",
            "\n",
            "Creating    dog select.mp4                                            OK\n",
            "Extracting  dog select.mp4/0.jpg                                         \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/1.jpg                                         \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/10.jpg                                        \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/100.jpg                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/101.jpg                                       \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/102.jpg                                       \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/103.jpg                                       \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/104.jpg                                       \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/105.jpg                                       \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/106.jpg                                       \b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/107.jpg                                       \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/108.jpg                                       \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/109.jpg                                       \b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/11.jpg                                        \b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/110.jpg                                       \b\b\b\b  8%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/111.jpg                                       \b\b\b\b  8%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/112.jpg                                       \b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/113.jpg                                       \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/114.jpg                                       \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/115.jpg                                       \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/116.jpg                                       \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/117.jpg                                       \b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/118.jpg                                       \b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/119.jpg                                       \b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/12.jpg                                        \b\b\b\b 14%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/120.jpg                                       \b\b\b\b 14%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/121.jpg                                       \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/122.jpg                                       \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/123.jpg                                       \b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/124.jpg                                       \b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/125.jpg                                       \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/126.jpg                                       \b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/127.jpg                                       \b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/128.jpg                                       \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/129.jpg                                       \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/13.jpg                                        \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/130.jpg                                       \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/131.jpg                                       \b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/132.jpg                                       \b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/133.jpg                                       \b\b\b\b 22%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/134.jpg                                       \b\b\b\b 22%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/135.jpg                                       \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/136.jpg                                       \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/137.jpg                                       \b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/138.jpg                                       \b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/139.jpg                                       \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/14.jpg                                        \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/140.jpg                                       \b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/141.jpg                                       \b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/142.jpg                                       \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/143.jpg                                       \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/144.jpg                                       \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/145.jpg                                       \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/146.jpg                                       \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/147.jpg                                       \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/148.jpg                                       \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/149.jpg                                       \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/15.jpg                                        \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/150.jpg                                       \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/151.jpg                                       \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/152.jpg                                       \b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/153.jpg                                       \b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/154.jpg                                       \b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/155.jpg                                       \b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/156.jpg                                       \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/157.jpg                                       \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/158.jpg                                       \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/159.jpg                                       \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/16.jpg                                        \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/160.jpg                                       \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/161.jpg                                       \b\b\b\b 38%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/162.jpg                                       \b\b\b\b 38%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/163.jpg                                       \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/164.jpg                                       \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/165.jpg                                       \b\b\b\b 40%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/166.jpg                                       \b\b\b\b 40%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/167.jpg                                       \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/168.jpg                                       \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/169.jpg                                       \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/17.jpg                                        \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/170.jpg                                       \b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/171.jpg                                       \b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/172.jpg                                       \b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/173.jpg                                       \b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/174.jpg                                       \b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/175.jpg                                       \b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/176.jpg                                       \b\b\b\b 46%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/177.jpg                                       \b\b\b\b 46%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/178.jpg                                       \b\b\b\b 47%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/179.jpg                                       \b\b\b\b 47%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/18.jpg                                        \b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/180.jpg                                       \b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/181.jpg                                       \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/182.jpg                                       \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/183.jpg                                       \b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/184.jpg                                       \b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/185.jpg                                       \b\b\b\b 51%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/186.jpg                                       \b\b\b\b 51%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/187.jpg                                       \b\b\b\b 52%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/188.jpg                                       \b\b\b\b 52%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/189.jpg                                       \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/19.jpg                                        \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/190.jpg                                       \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/191.jpg                                       \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/192.jpg                                       \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/193.jpg                                       \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/2.jpg                                         \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/20.jpg                                        \b\b\b\b 56%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/21.jpg                                        \b\b\b\b 56%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/22.jpg                                        \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/23.jpg                                        \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/24.jpg                                        \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/25.jpg                                        \b\b\b\b 59%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/26.jpg                                        \b\b\b\b 59%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/27.jpg                                        \b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/28.jpg                                        \b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/29.jpg                                        \b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/3.jpg                                         \b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/30.jpg                                        \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/31.jpg                                        \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/32.jpg                                        \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/33.jpg                                        \b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/34.jpg                                        \b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/35.jpg                                        \b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/36.jpg                                        \b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/37.jpg                                        \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/38.jpg                                        \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/39.jpg                                        \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/4.jpg                                         \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/40.jpg                                        \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/41.jpg                                        \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/42.jpg                                        \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/43.jpg                                        \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/44.jpg                                        \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/45.jpg                                        \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/46.jpg                                        \b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/47.jpg                                        \b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/48.jpg                                        \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/49.jpg                                        \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/5.jpg                                         \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/50.jpg                                        \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/51.jpg                                        \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/52.jpg                                        \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/53.jpg                                        \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/54.jpg                                        \b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/55.jpg                                        \b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/56.jpg                                        \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/57.jpg                                        \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/58.jpg                                        \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/59.jpg                                        \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/6.jpg                                         \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/60.jpg                                        \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/61.jpg                                        \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/62.jpg                                        \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/63.jpg                                        \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/64.jpg                                        \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/65.jpg                                        \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/66.jpg                                        \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/67.jpg                                        \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/68.jpg                                        \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/69.jpg                                        \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/7.jpg                                         \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/70.jpg                                        \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/71.jpg                                        \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/72.jpg                                        \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/73.jpg                                        \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/74.jpg                                        \b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/75.jpg                                        \b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/76.jpg                                        \b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/77.jpg                                        \b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/78.jpg                                        \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/79.jpg                                        \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/8.jpg                                         \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/80.jpg                                        \b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/81.jpg                                        \b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/82.jpg                                        \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/83.jpg                                        \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/84.jpg                                        \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/85.jpg                                        \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/86.jpg                                        \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/87.jpg                                        \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/88.jpg                                        \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/89.jpg                                        \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/9.jpg                                         \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/90.jpg                                        \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/91.jpg                                        \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/92.jpg                                        \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/93.jpg                                        \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/94.jpg                                        \b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/95.jpg                                        \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/96.jpg                                        \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/97.jpg                                        \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/98.jpg                                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  dog select.mp4/99.jpg                                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zs8MhJJms5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "zipObj = ZipFile('video_1.zip', 'w')\n",
        "os.mkdir('video_1/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy2P7-PH7Wkr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1241781a-ab55-4e0a-d990-62736035ae0d"
      },
      "source": [
        "for i in range(len(data_video.path_img)):\n",
        "#for i in range(3):\n",
        "  input, target = data_video.create_data_video(i)\n",
        "  model_gan.generate_images_2(input, target, save_results= True,    index_file = 'video_1/' + str(i) )\n",
        "  zipObj.write('video_1/' + str(i) + '.png')\n",
        "  #files.download('video_1/' + str(i) + '.png')   #guardar imagen por imagen\n",
        "zipObj.close()\n",
        "files.download('video_1.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_28b5105c-3f85-40b9-aeee-68ac74ca1cf6\", \"video_1.zip\", 19850797)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X4_jSvk500f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOVh8-OZApcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}